"""
ì¶˜ì²œì‹œ AI ì±—ë´‡ Streamlit ì•± - ì™„ì „ ìƒˆë¡œìš´ ë””ìì¸
"""

import streamlit as st
import os
from datetime import datetime
import uuid
from typing import List, Dict, Any

# AI ë¼ì´ë¸ŒëŸ¬ë¦¬ import
try:
    from langchain_openai import ChatOpenAI, OpenAIEmbeddings
    from langchain_community.vectorstores import FAISS
    from langchain_community.retrievers import TavilySearchAPIRetriever
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.runnables import RunnablePassthrough, RunnableLambda
    from langchain.chains import LLMChain
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain.schema import Document
    import pandas as pd
    import numpy as np
    import glob
    import requests
    import json
except ImportError as e:
    st.error(f"âŒ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    st.stop()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì¶˜ì²œì‹œ AI ë„ìš°ë¯¸ - ì¶˜ì´",
    page_icon="ğŸŒ¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# API í‚¤ ì„¤ì •
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
if "TAVILY_API_KEY" in st.secrets:
    os.environ["TAVILY_API_KEY"] = st.secrets["TAVILY_API_KEY"]

# ê³µê³µë°ì´í„° API í‚¤
PUBLIC_API_KEY = "o2Ly83v52XUaFEc1EFz+VgHoNb2ErLSGPrkhn4wJ3J+478HUZCgn6DGzq7IHLKGU6C75oIpQYQvItH9nTRzamQ=="

# ìŠ¤íŠ¸ë¦¼ë¦¿ì— ìµœì í™”ëœ CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    }
    
    .chat-message {
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 15px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    
    .user-message {
        background: linear-gradient(135deg, #667eea, #764ba2);
        color: white;
        margin-left: 25%;
        text-align: right;
    }
    
    .bot-message {
        background-color: #f8f9fa;
        border: 1px solid #e9ecef;
        margin-right: 25%;
    }
    
    .stButton > button {
        width: 100%;
        border-radius: 25px;
        border: 2px solid #667eea;
        color: #667eea;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        background: linear-gradient(135deg, #667eea, #764ba2);
        color: white;
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
    }
    
    .footer-info {
        text-align: center;
        color: #6b7280;
        padding: 1rem;
        border-top: 1px solid #e5e7eb;
        margin-top: 2rem;
    }
    
    .welcome-box {
        background: linear-gradient(135deg, #f8f9fa, #e9ecef);
        padding: 2rem;
        border-radius: 15px;
        text-align: center;
        margin: 1rem 0;
        border: 1px solid #dee2e6;
    }
</style>
""", unsafe_allow_html=True)

class ChuncheonDataLoader:
    """ì¶˜ì²œì‹œ ë°ì´í„° ë¡œë” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.data_folders = [
            "dataSet",
            "dataset2", 
            "ë¯¼ì› ê´€ë ¨"
        ]
        self.all_data = []
    
    def load_csv_data(self) -> List[Document]:
        """ëª¨ë“  CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ - í† í° ì œí•œ ê³ ë ¤"""
        documents = []
        max_documents = 100  # ë¬¸ì„œ ìˆ˜ ì œí•œ
        
        for folder in self.data_folders:
            folder_path = os.path.join(os.getcwd(), folder)
            if not os.path.exists(folder_path):
                continue
                
            csv_files = glob.glob(os.path.join(folder_path, "*.csv")) + glob.glob(os.path.join(folder_path, "*.CSV"))
            
            for file_path in csv_files[:2]:  # íŒŒì¼ ìˆ˜ ì œí•œ
                try:
                    df = pd.read_csv(file_path, encoding='utf-8')
                except UnicodeDecodeError:
                    try:
                        df = pd.read_csv(file_path, encoding='cp949')
                    except:
                        continue
                
                filename = os.path.basename(file_path)
                
                # í–‰ ìˆ˜ ì œí•œ
                for idx, row in df.head(50).iterrows():
                    if len(documents) >= max_documents:
                        break
                        
                    content = f"íŒŒì¼: {filename}\n"
                    for col in df.columns:
                        if pd.notna(row[col]):
                            # ê¸´ í…ìŠ¤íŠ¸ ìë¥´ê¸°
                            value = str(row[col])[:200]
                            content += f"{col}: {value}\n"
                    
                    documents.append(Document(
                        page_content=content,
                        metadata={"source": filename, "row_id": idx}
                    ))
                
                if len(documents) >= max_documents:
                    break
        
        return documents

class EnhancedChuncheonChatbot:
    """RAG ê¸°ë°˜ ì¶˜ì²œì‹œ ì±—ë´‡"""
    
    def __init__(self):
        # API í‚¤ ì„¤ì •
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.tavily_api_key = os.getenv("TAVILY_API_KEY")
        
        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        self.data_loader = ChuncheonDataLoader()
        
        # ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”
        self.embeddings = OpenAIEmbeddings()
        self.vector_store = None
        self.retriever = None
        
        # Tavily ê²€ìƒ‰ ì´ˆê¸°í™”
        self.tavily_retriever = None
        if self.tavily_api_key:
            try:
                self.tavily_retriever = TavilySearchAPIRetriever(
                    k=3,
                    api_key=self.tavily_api_key
                )
            except Exception as e:
                st.warning(f"Tavily ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # LLM ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.7
        )
        
        # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        self._create_vector_store()
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.prompt_template = """ë‹¹ì‹ ì€ 'ì¶˜ì´'ë¼ëŠ” ì´ë¦„ì˜ ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì¶˜ì²œì‹œ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

# í•„ìˆ˜ ì§€ì¹¨:
1. í•­ìƒ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” íƒœë„ë¡œ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”
2. **ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ê°€ì§œ ì •ë³´ë¥¼ ë§Œë“¤ì§€ ë§ˆì„¸ìš”**
3. **ì£¼ì†Œ, ì „í™”ë²ˆí˜¸, ì˜ì—…ì‹œê°„ ë“± êµ¬ì²´ì  ì •ë³´ëŠ” ë°˜ë“œì‹œ ì œê³µëœ ë°ì´í„°ì—ì„œë§Œ ì‚¬ìš©í•˜ì„¸ìš”**
4. ì •ë³´ê°€ ì—†ìœ¼ë©´ "ì •í™•í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”
5. ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”
6. ì¶˜ì²œì‹œì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”

# í˜„ì¬ ì‹œê°: {current_time}

# ê´€ë ¨ ë°ì´í„°:
{context}

# ì›¹ ê²€ìƒ‰ ê²°ê³¼:
{web_results}

# ì‚¬ìš©ì ì§ˆë¬¸: {question}

ë‹µë³€:"""
        
        self.prompt = ChatPromptTemplate.from_template(self.prompt_template)
        self.chain = LLMChain(llm=self.llm, prompt=self.prompt)
    
    def _create_vector_store(self):
        """ë²¡í„°ìŠ¤í† ì–´ ìƒì„±"""
        try:
            documents = self.data_loader.load_csv_data()
            
            if documents:
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=500,
                    chunk_overlap=50
                )
                splits = text_splitter.split_documents(documents)
                
                # ë°°ì¹˜ ì²˜ë¦¬ë¡œ í† í° ì œí•œ ë°©ì§€
                batch_size = 20
                if len(splits) > batch_size:
                    splits = splits[:batch_size]
                
                self.vector_store = FAISS.from_documents(
                    documents=splits,
                    embedding=self.embeddings
                )
                self.retriever = self.vector_store.as_retriever(search_kwargs={"k": 5})
                
        except Exception as e:
            st.warning(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def generate_response(self, message: str) -> str:
        """ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±"""
        try:
            current_time = datetime.now().strftime("%Yë…„ %mì›” %dì¼ %H:%M")
            
            # RAG ê²€ìƒ‰
            context = ""
            if self.retriever:
                try:
                    docs = self.retriever.get_relevant_documents(message)
                    context = "\n\n".join([doc.page_content for doc in docs[:3]])
                except:
                    context = "ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ì›¹ ê²€ìƒ‰
            web_results = ""
            if self.tavily_retriever:
                try:
                    web_docs = self.tavily_retriever.get_relevant_documents(f"ì¶˜ì²œì‹œ {message}")
                    web_results = "\n\n".join([doc.page_content for doc in web_docs[:2]])
                except:
                    web_results = "ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            response = self.chain.invoke({
                "question": message,
                "current_time": current_time,
                "context": context,
                "web_results": web_results
            })
            
            if isinstance(response, dict):
                return response.get('text', str(response))
            elif hasattr(response, 'content'):
                return response.content
            else:
                return str(response)
                
        except Exception as e:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def initialize_chatbot():
    """RAG ì±—ë´‡ ì´ˆê¸°í™” - ìºì‹œ ì œê±°ë¡œ ë¬¸ì œ í•´ê²°"""
    try:
        with st.spinner("ğŸš€ ì¶˜ì²œì‹œ RAG ì±—ë´‡ ì´ˆê¸°í™” ì¤‘..."):
            chatbot = EnhancedChuncheonChatbot()
        st.success("âœ… ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ!")
        return chatbot
    except Exception as e:
        st.error(f"âŒ ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.info("ğŸ’¡ Streamlit Cloud Secretsì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return None

def main():
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'chatbot_ready' not in st.session_state:
        st.session_state.chatbot_ready = False
    
    # í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h1>ğŸŒ¸ ì¶˜ì²œì‹œ AI ë„ìš°ë¯¸ ì¶˜ì´ ğŸŒ¸</h1>
        <p>ì¶˜ì²œì‹œ ê´€ê´‘, í–‰ì‚¬, ë§›ì§‘ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì•Œë ¤ë“œë ¤ìš”!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ì±—ë´‡ ì´ˆê¸°í™”
    chatbot = initialize_chatbot()
    if not chatbot:
        st.warning("âš ï¸ ì±—ë´‡ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # ë©”ì¸ ì»¨í…Œì´ë„ˆ
    col1, col2, col3 = st.columns([1, 4, 1])
    
    with col2:
        # í™˜ì˜ ë©”ì‹œì§€
        if not st.session_state.messages:
            st.markdown("""
            <div class="welcome-box">
                <h3>ğŸ‘‹ ì•ˆë…•í•˜ì„¸ìš”!</h3>
                <p>ì¶˜ì²œì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!</p>
                <p>ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.</p>
            </div>
            """, unsafe_allow_html=True)
        
        # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
        chat_container = st.container()
        with chat_container:
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.write(message["content"])
        
        # ë¹ ë¥¸ ì§ˆë¬¸ ë²„íŠ¼ë“¤
        st.markdown("### ğŸš€ ë¹ ë¥¸ ì§ˆë¬¸")
        
        # 2í–‰ 4ì—´ë¡œ ë°°ì¹˜
        row1_cols = st.columns(4)
        row2_cols = st.columns(4)
        
        quick_questions = [
            "ì¶˜ì²œ ë‹­ê°ˆë¹„ ë§›ì§‘ ì¶”ì²œí•´ì¤˜",
            "ì´ë²ˆ ì£¼ ì¶˜ì²œ í–‰ì‚¬ ë­ ìˆì–´?",
            "ì¶˜ì²œ ì „ê¸°ì°¨ ì¶©ì „ì†Œ ì–´ë”” ìˆì–´?",
            "ì¶˜ì²œ ê´€ê´‘ì§€ ì¶”ì²œí•´ì¤˜",
            "ì¶˜ì²œì‹œ ì²­ë…„ ì •ì±… ì•Œë ¤ì¤˜",
            "ì¶˜ì²œ ì¹´í˜ ì¶”ì²œí•´ì¤˜",
            "ì¶˜ì²œ ìˆ™ë°•ì‹œì„¤ ì•Œë ¤ì¤˜",
            "ì‹œì²­ ì—°ë½ì²˜ ì•Œë ¤ì¤˜"
        ]
        
        # ì²« ë²ˆì§¸ í–‰
        for i, question in enumerate(quick_questions[:4]):
            with row1_cols[i]:
                if st.button(question, key=f"quick_{i}"):
                    st.session_state.messages.append({"role": "user", "content": question})
                    
                    # AI ì‘ë‹µ ìƒì„±
                    with st.spinner("ì¶˜ì´ê°€ ìƒê°ì¤‘..."):
                        response = chatbot.generate_response(question)
                        st.session_state.messages.append({"role": "assistant", "content": response})
                    
                    st.rerun()
        
        # ë‘ ë²ˆì§¸ í–‰
        for i, question in enumerate(quick_questions[4:]):
            with row2_cols[i]:
                if st.button(question, key=f"quick_{i+4}"):
                    st.session_state.messages.append({"role": "user", "content": question})
                    
                    # AI ì‘ë‹µ ìƒì„±
                    with st.spinner("ì¶˜ì´ê°€ ìƒê°ì¤‘..."):
                        response = chatbot.generate_response(question)
                        st.session_state.messages.append({"role": "assistant", "content": response})
                    
                    st.rerun()
        
        # ì±„íŒ… ì…ë ¥
        st.markdown("### ğŸ’¬ ì§ì ‘ ì§ˆë¬¸í•˜ê¸°")
        user_input = st.chat_input("ì¶˜ì²œì— ëŒ€í•´ ë­ë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”...")
        
        if user_input:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": user_input})
            
            # AI ì‘ë‹µ ìƒì„± ë° ì„¸ì…˜ì— ì €ì¥
            with st.spinner("ì¶˜ì´ê°€ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                response = chatbot.generate_response(user_input)
                st.session_state.messages.append({"role": "assistant", "content": response})
            
            st.rerun()
    
    # í•˜ë‹¨ ì •ë³´
    st.markdown("""
    <div class="footer-info">
        <p>ğŸŒ¸ <strong>ì¶˜ì²œì‹œ AI ë„ìš°ë¯¸ ì¶˜ì´</strong> - 2025ë…„ í”„ë¡¬í”„í†¤ ì¶œí’ˆì‘ ğŸŒ¸</p>
        <p>ê°œë°œíŒ€: ê¹€ì¬í˜•(íŒ€ì¥), ê¹€ì„±í˜¸, ê¹€ê°•ë¯¼ | í•œë¦¼ëŒ€í•™êµ</p>
        <p>ğŸ›ï¸ ì¶˜ì²œì‹œ ì£¼ìš” ì •ë³´:
- ë‹­ê°ˆë¹„: ì¶˜ì²œì˜ ëŒ€í‘œ ìŒì‹, ì¤‘ì•™ë¡œ ì¼ëŒ€ì— ë§ì€ ë§›ì§‘
- ë§‰êµ­ìˆ˜: ì¶˜ì²œì˜ ë˜ ë‹¤ë¥¸ íŠ¹ì‚°í’ˆ
- ë‚¨ì´ì„¬: ëŒ€í‘œì ì¸ ê´€ê´‘ì§€
- ì†Œì–‘ê°•ëŒ: ì¶˜ì²œì˜ ëœë“œë§ˆí¬
- ì¶˜ì²œì‹œì²­: 033-250-3000
- ê°•ì›ëŒ€í•™êµ: ì¶˜ì²œìº í¼ìŠ¤ ìœ„ì¹˜, ì´ì¥ì€ ê¹€í—Œì˜ (2023ë…„ ê¸°ì¤€)
- í•œë¦¼ëŒ€í•™êµ: ì¶˜ì²œì‹œ í•œë¦¼ëŒ€í•™ê¸¸ 1 ìœ„ì¹˜ | ğŸš‚ ì¶˜ì²œì—­: 1544-7788 | ğŸ— íŠ¹ì‚°í’ˆ: ë‹­ê°ˆë¹„, ë§‰êµ­ìˆ˜</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
